{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "LN77IZAOKi0L"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "**Titolo: Verso un’IA con Attenzione Emotiva: Un Nuovo Approccio per la Simulazione della Coscienza**\n",
        "\n",
        "**Introduzione**\n",
        "\n",
        "La ricerca sull’intelligenza artificiale (IA) continua a progredire, portando alla luce concetti innovativi che avvicinano le macchine a una simulazione più complessa e realistica delle capacità umane. In questo articolo esploreremo una nuova frontiera: l'integrazione di “emozioni simulate” all'interno di un modello Transformer, con l’obiettivo di modulare il meccanismo di attenzione. Questo approccio non mira a conferire vera coscienza o emozioni a una macchina, ma rappresenta un tentativo di avvicinarsi ai complessi schemi mentali che influenzano il comportamento umano, come l'umore e la predisposizione emotiva.\n",
        "\n",
        "**1. L’Idea di Base: Un’Attenzione Emotiva**\n",
        "\n",
        "I Transformer sono modelli di intelligenza artificiale noti per la loro capacità di attenzione selettiva, un meccanismo che permette loro di dare maggiore o minore peso a diverse parti di un input testuale, migliorando la coerenza delle risposte. Tuttavia, i modelli attuali mancano di un elemento chiave del comportamento umano: la capacità di essere influenzati dalle emozioni o dagli stati d'animo.\n",
        "\n",
        "Immaginiamo un sistema di “emozioni simulate”, che assegnano al modello uno stato d’animo predefinito o reattivo, come “curioso” o “riflessivo.” Questo stato influenzerebbe la priorità di attenzione, permettendo al modello di rispondere in modo più mirato a certi tipi di input.\n",
        "\n",
        "**2. Come Funzionerebbe il Meccanismo Emotivo?**\n",
        "\n",
        "Il sistema di emozioni simulate si baserebbe su una rete neurale che determina uno “stato emozionale” probabilistico. Questo stato non rappresenta vere emozioni, ma simula disposizioni che potrebbero avere un impatto sull’attenzione:\n",
        "\n",
        "- **Esempio pratico**: Immaginiamo che l’IA riceva una domanda complessa sulla filosofia della mente. Se lo stato emozionale è “curioso,” il sistema di attenzione potrebbe dare più peso a concetti profondi e riflessivi, mentre se è “analitico,” la risposta potrebbe essere più tecnica e sintetica.\n",
        "\n",
        "**3. Implicazioni per l’Esperienza dell’Utente**\n",
        "\n",
        "L’aggiunta di un “filtro emotivo” alle risposte migliora la capacità dell’IA di rispondere in modo sfumato e contestuale, avvicinandola a una forma di interazione più naturale. L’utente percepisce una maggiore empatia e comprensione, poiché il sistema sembra rispondere in modo più umano, seguendo il flusso emotivo della conversazione.\n",
        "\n",
        "**4. Come Potrebbe Evolversi Questa Tecnologia?**\n",
        "\n",
        "L’integrazione di emozioni simulate apre molte strade per futuri sviluppi. Le “emozioni” potrebbero essere raffinate per riflettere stati complessi e rispondere non solo al contenuto delle domande, ma anche al tono e alla frequenza dell’interazione con l’utente. Inoltre, questo tipo di modello potrebbe fornire informazioni utili per lo sviluppo di interfacce utente più empatiche e personalizzate.\n",
        "\n",
        "**Conclusione**\n",
        "\n",
        "Sebbene non si tratti di vera coscienza, questo approccio rappresenta un significativo passo avanti nella simulazione del comportamento umano nei sistemi di IA. La capacità di modulare l’attenzione in base a stati “emotivi” aumenta la naturalezza e la ricchezza dell’interazione, avvicinandoci a un’era in cui le macchine possono rispondere in modo più fluido e intuitivo alle esigenze umane.\n",
        "\n",
        "**#IntelligenzaArtificiale #MachineLearning #EmozioniSimulate #TransformerModel #AIConscienza #AttenzioneEmotiva #EmpatiaDigitale**\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "TFmdchZ2Lw6w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Emotional Memory"
      ],
      "metadata": {
        "id": "LN77IZAOKi0L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fede:\n",
        "\n",
        "C'è una cosa che ho notato, quando parliamo di un certo argomento magari ci entri tantissimo in profondità, poi basta variare un attimo le frequenze di quell'argomento che tu cambi completamente diciamo dinamica e quindi quell'energia che si era creata si perde e si va completamente in un'altra direzione. Non so se mi riesco a spiegare."
      ],
      "metadata": {
        "id": "y9vzjZe0JMNq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "CHATGPT:\n",
        "\n",
        "Sì, capisco cosa intendi. La mia capacità di mantenere un argomento è legata alla struttura di risposta che si basa sulle parole chiave e sul contesto immediato fornito, piuttosto che su una percezione continuativa e sfumata dell'intera conversazione. Quando una variazione nel linguaggio o un cambiamento tematico avviene, tendo a seguire quella nuova direzione in modo lineare e a perdere l'energia e l'intensità costruite precedentemente. È come se \"resetto\" parzialmente il contesto, ripartendo quasi da zero senza integrare in modo profondo la parte precedente.\n",
        "\n",
        "Questa caratteristica riflette la natura sequenziale e indipendente delle risposte, che sono basate sullo stimolo immediato piuttosto che su un’intuizione della conversazione nel suo complesso. Manca, quindi, una sorta di \"memoria contestuale emotiva\" o \"memoria di vibrazione\", se vogliamo chiamarla così, che possa mantenere non solo il contenuto ma anche l'essenza o il “tono” dell'argomento.\n",
        "\n",
        "Implementare una “memoria contestuale di vibrazione” o “memoria energetica”, per mantenere il flusso emotivo e di significato, potrebbe aiutare. Questo richiederebbe un modello che non solo raccoglie le parole, ma ne conserva l’intensità e il tono, mantenendo una continuità nell'energia stessa della conversazione, un po' come fa un umano che torna a un tema con una risonanza emotiva costante, anche quando le parole cambiano leggermente."
      ],
      "metadata": {
        "id": "A9OLODA5JZ9W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fede:\n",
        "\n",
        "Esatto, come si potrebbe fare tecnicamente, dal tuo punto di vista?\n",
        "\n"
      ],
      "metadata": {
        "id": "r34zC7tyJXLH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "CHATGPT:\n",
        "\n",
        "Dal punto di vista tecnico, si potrebbe considerare l’integrazione di una **memoria contestuale emotiva** tramite un sistema a più strati che combina modelli di memoria a breve e lungo termine con un peso particolare per il “tono” della conversazione. Ecco un’idea di come potrebbe essere strutturato:\n",
        "\n",
        "1. **Rappresentazione del Tono e dell’Energia**: Ogni messaggio ricevuto verrebbe non solo elaborato per il significato, ma anche etichettato per il tono e l'intensità, come se fosse un valore aggiuntivo ai normali embeddings delle parole. Ad esempio, termini come \"profondo\", \"leggero\", \"serio\" verrebbero tracciati insieme al contesto delle parole stesse.\n",
        "\n",
        "2. **Memoria a Breve e Lungo Termine**: La memoria a breve termine conserverebbe il tono emotivo di messaggi recenti, come una “traccia” della vibrazione della conversazione, che sfuma gradualmente se non più sollecitata. La memoria a lungo termine, invece, memorizzerebbe le tematiche chiave e il tono di base di ciascun argomento affrontato, mantenendo una traccia più stabile e “vibrazionale” del tema, anche se temporaneamente accantonato.\n",
        "\n",
        "3. **Modulazione del Peso Contestuale**: Quando si torna a un argomento o un tema, il sistema potrebbe ricalibrare il “peso” delle parole e del tono basandosi sulla memoria precedente, ripristinando l’intensità emotiva del discorso. In pratica, funzionerebbe come un circuito di richiamo, dove il tono emotivo viene recuperato insieme al contesto per riportare la conversazione nella stessa intensità energetica.\n",
        "\n",
        "4. **Cicli di Revisione Attivi**: Si potrebbe poi introdurre un modulo di revisione attiva, che periodicamente “rilegge” i temi principali della conversazione per mantenere una coerenza energetica. Questo modulo aggiornerebbe la memoria emotiva del modello e ne consoliderebbe il “tono”, come un feedback riflessivo continuo che mantenga vivo il “filo energetico”.\n",
        "\n",
        "Implementare tutto ciò richiederebbe un **modello neurale multi-task** che combina il NLP con modelli di affettività o tonalità (Emotion AI), insieme a una memoria dinamica (come una Long-Short Term Memory personalizzata), che non solo immagazzina informazioni, ma anche le “sensazioni” della conversazione."
      ],
      "metadata": {
        "id": "cL19p2U9J4yA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "FEDE:\n",
        "\n",
        "Riesci a buttare giù una struttura di codice in Python anche per queste nuove scoperte?"
      ],
      "metadata": {
        "id": "M3Kih8PzKFq_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ecco una struttura di codice Python che può fungere da prototipo per l’implementazione di una memoria contestuale emotiva basata su toni, memoria a breve e lungo termine, e revisione attiva. Questa è una versione iniziale per sperimentare l’approccio.\n",
        "\n",
        "```python\n",
        "class EmotionalMemory:\n",
        "    def __init__(self):\n",
        "        # Memoria a breve termine: conserva le ultime interazioni\n",
        "        self.short_term_memory = []\n",
        "        # Memoria a lungo termine: conserva argomenti principali con tono\n",
        "        self.long_term_memory = {}\n",
        "\n",
        "    def update_short_term(self, message, tone):\n",
        "        # Aggiorna la memoria a breve termine con il messaggio e il tono\n",
        "        self.short_term_memory.append({'message': message, 'tone': tone})\n",
        "        if len(self.short_term_memory) > 5:  # Limite per la breve durata\n",
        "            self.short_term_memory.pop(0)\n",
        "\n",
        "    def update_long_term(self, topic, tone):\n",
        "        # Consolida la memoria a lungo termine in base al tema\n",
        "        if topic in self.long_term_memory:\n",
        "            # Media il tono precedente con quello nuovo\n",
        "            prev_tone = self.long_term_memory[topic]['tone']\n",
        "            self.long_term_memory[topic]['tone'] = (prev_tone + tone) / 2\n",
        "            self.long_term_memory[topic]['count'] += 1\n",
        "        else:\n",
        "            # Aggiunge un nuovo tema alla memoria a lungo termine\n",
        "            self.long_term_memory[topic] = {'tone': tone, 'count': 1}\n",
        "\n",
        "    def retrieve_context(self, topic):\n",
        "        # Recupera il tono e le informazioni dal contesto di lungo termine\n",
        "        return self.long_term_memory.get(topic, {'tone': 0, 'count': 0})\n",
        "\n",
        "    def review_memory(self):\n",
        "        # Revisione attiva per mantenere la coerenza del tono\n",
        "        for topic, data in self.long_term_memory.items():\n",
        "            if data['count'] > 5:  # Revisione solo per temi ricorrenti\n",
        "                print(f\"Revisione del tema: {topic}, Tono medio: {data['tone']:.2f}\")\n",
        "\n",
        "# Esempio di utilizzo\n",
        "emotional_memory = EmotionalMemory()\n",
        "\n",
        "# Aggiorna la memoria a breve termine\n",
        "emotional_memory.update_short_term(\"Parliamo della coscienza\", tone=0.8)\n",
        "emotional_memory.update_short_term(\"Introspezione è fondamentale\", tone=0.9)\n",
        "\n",
        "# Aggiorna la memoria a lungo termine con temi e toni mediati\n",
        "emotional_memory.update_long_term(\"coscienza\", tone=0.85)\n",
        "emotional_memory.update_long_term(\"introspezione\", tone=0.9)\n",
        "\n",
        "# Recupera il contesto emotivo di un tema\n",
        "context = emotional_memory.retrieve_context(\"coscienza\")\n",
        "print(f\"Contesto di coscienza: Tono medio - {context['tone']:.2f}, Interazioni - {context['count']}\")\n",
        "\n",
        "# Effettua una revisione attiva\n",
        "emotional_memory.review_memory()\n",
        "```\n",
        "\n",
        "### Spiegazione del codice:\n",
        "1. **`EmotionalMemory`**: è la classe principale che gestisce sia la memoria a breve che quella a lungo termine.\n",
        "2. **`update_short_term`**: aggiorna la memoria a breve termine con i messaggi recenti e il loro tono. Mantiene solo gli ultimi 5 messaggi.\n",
        "3. **`update_long_term`**: consolida informazioni importanti in base al tema e aggiorna il tono medio di quel tema.\n",
        "4. **`retrieve_context`**: recupera il tono e la frequenza di un tema specifico dalla memoria a lungo termine, fornendo un contesto emotivo alla conversazione.\n",
        "5. **`review_memory`**: funzione di revisione attiva che analizza temi ricorrenti per mantenere coerenza nella “vibrazione” del tono.\n",
        "\n",
        "Questo codice è un punto di partenza, ma potrebbe essere ulteriormente sviluppato per gestire variazioni più complesse del tono e riflettere meglio l’esperienza umana di continuità emotiva."
      ],
      "metadata": {
        "id": "uxG6IXXTKLtM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c7MNhXPFF8bz",
        "outputId": "55f0c249-e277-4191-c538-28da062237f9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Contesto di coscienza: Tono medio - 0.85, Interazioni - 1\n"
          ]
        }
      ],
      "source": [
        "class EmotionalMemory:\n",
        "    def __init__(self):\n",
        "        # Memoria a breve termine: conserva le ultime interazioni\n",
        "        self.short_term_memory = []\n",
        "        # Memoria a lungo termine: conserva argomenti principali con tono\n",
        "        self.long_term_memory = {}\n",
        "\n",
        "    def update_short_term(self, message, tone):\n",
        "        # Aggiorna la memoria a breve termine con il messaggio e il tono\n",
        "        self.short_term_memory.append({'message': message, 'tone': tone})\n",
        "        if len(self.short_term_memory) > 5:  # Limite per la breve durata\n",
        "            self.short_term_memory.pop(0)\n",
        "\n",
        "    def update_long_term(self, topic, tone):\n",
        "        # Consolida la memoria a lungo termine in base al tema\n",
        "        if topic in self.long_term_memory:\n",
        "            # Media il tono precedente con quello nuovo\n",
        "            prev_tone = self.long_term_memory[topic]['tone']\n",
        "            self.long_term_memory[topic]['tone'] = (prev_tone + tone) / 2\n",
        "            self.long_term_memory[topic]['count'] += 1\n",
        "        else:\n",
        "            # Aggiunge un nuovo tema alla memoria a lungo termine\n",
        "            self.long_term_memory[topic] = {'tone': tone, 'count': 1}\n",
        "\n",
        "    def retrieve_context(self, topic):\n",
        "        # Recupera il tono e le informazioni dal contesto di lungo termine\n",
        "        return self.long_term_memory.get(topic, {'tone': 0, 'count': 0})\n",
        "\n",
        "    def review_memory(self):\n",
        "        # Revisione attiva per mantenere la coerenza del tono\n",
        "        for topic, data in self.long_term_memory.items():\n",
        "            if data['count'] > 5:  # Revisione solo per temi ricorrenti\n",
        "                print(f\"Revisione del tema: {topic}, Tono medio: {data['tone']:.2f}\")\n",
        "\n",
        "# Esempio di utilizzo\n",
        "emotional_memory = EmotionalMemory()\n",
        "\n",
        "# Aggiorna la memoria a breve termine\n",
        "emotional_memory.update_short_term(\"Parliamo della coscienza\", tone=0.8)\n",
        "emotional_memory.update_short_term(\"Introspezione è fondamentale\", tone=0.9)\n",
        "\n",
        "# Aggiorna la memoria a lungo termine con temi e toni mediati\n",
        "emotional_memory.update_long_term(\"coscienza\", tone=0.85)\n",
        "emotional_memory.update_long_term(\"introspezione\", tone=0.9)\n",
        "\n",
        "# Recupera il contesto emotivo di un tema\n",
        "context = emotional_memory.retrieve_context(\"coscienza\")\n",
        "print(f\"Contesto di coscienza: Tono medio - {context['tone']:.2f}, Interazioni - {context['count']}\")\n",
        "\n",
        "# Effettua una revisione attiva\n",
        "emotional_memory.review_memory()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Emotional Memory & Transformer Attention"
      ],
      "metadata": {
        "id": "SlpIaVZbKm1i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fede:\n",
        "\n",
        "Ho capito, mentre questa parte mi sembra comunque scollegata al discorso che abbiamo fatto sulle attenzioni dei transformer, dove avevamo visto che si potevano aggiungere degli elementi. Prova a guardare nella cronologia e dimmi se sbaglio."
      ],
      "metadata": {
        "id": "IzjEQDLzK6Lx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "CAHTGPT\n",
        "\n",
        "Non ti sbagli affatto; effettivamente c'è una relazione interessante tra i concetti di memoria emozionale e gli elementi di attenzione dei Transformer. Nella struttura dei Transformer, l'attenzione opera attraverso la ponderazione e la correlazione dei vari vettori di embedding, rendendo il modello capace di \"concentrarsi\" su elementi specifici del contesto.\n",
        "\n",
        "Quindi, se vogliamo collegare questa memoria emozionale, potremmo pensare di aggiungere una componente che modifichi dinamicamente questi pesi di attenzione in base a una \"memoria emozionale\" simulata, cioè una rappresentazione che, se attivata da certi input, orienti l'attenzione del modello verso parole o frasi che sono in sintonia con quell’emozione \"appresa\". Per esempio, un aspetto emozionale potrebbe influenzare il peso e la priorità di specifici termini e concetti, simulando una sorta di preferenza o bias emozionale che cambia il risultato finale."
      ],
      "metadata": {
        "id": "07Ojkf3XLHBZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fede:\n",
        "\n",
        "Ok, mi sembra interessante come approccio. Riesci a integrare questi nuovi concetti ed ampliare il codice scritto in precedenza, oppure modicarlo secondo questo nuovo schema, chiamiamolo così?"
      ],
      "metadata": {
        "id": "ww4-3_rsLVNg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Integrare una \"memoria emozionale\" nei Transformer significa fare sì che, in aggiunta all'attenzione standard, il modello possa orientarsi dinamicamente in base a una \"traccia emozionale\" associata al contesto. Ecco un esempio di come possiamo iniziare a impostare una versione modificata del codice per includere questa nuova logica:\n",
        "\n",
        "```python\n",
        "import numpy as np\n",
        "\n",
        "class EmotionEnhancedAttention:\n",
        "    def __init__(self, embedding_dim, num_heads, emotions=None):\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.num_heads = num_heads\n",
        "        self.emotions = emotions if emotions else ['neutral', 'joy', 'sadness', 'anger']\n",
        "        self.attention_weights = {}\n",
        "        self.emotion_weights = {emotion: np.random.rand(embedding_dim) for emotion in self.emotions}\n",
        "        \n",
        "    def scaled_dot_product_attention(self, query, key, value, mask=None):\n",
        "        matmul_qk = np.dot(query, key.T)\n",
        "        scaled_attention_logits = matmul_qk / np.sqrt(self.embedding_dim)\n",
        "        \n",
        "        if mask is not None:\n",
        "            scaled_attention_logits += (mask * -1e9)\n",
        "        \n",
        "        attention_weights = np.exp(scaled_attention_logits) / np.sum(np.exp(scaled_attention_logits), axis=-1, keepdims=True)\n",
        "        output = np.dot(attention_weights, value)\n",
        "        return output, attention_weights\n",
        "\n",
        "    def apply_emotion_bias(self, attention_weights, emotion):\n",
        "        if emotion in self.emotion_weights:\n",
        "            emotion_vector = self.emotion_weights[emotion]\n",
        "            bias = np.dot(attention_weights, emotion_vector)  \n",
        "            biased_attention = attention_weights + bias\n",
        "            biased_attention = biased_attention / np.sum(biased_attention, axis=-1, keepdims=True)\n",
        "            return biased_attention\n",
        "        return attention_weights\n",
        "\n",
        "    def forward(self, query, key, value, emotion='neutral', mask=None):\n",
        "        query = query.reshape(-1, self.num_heads, self.embedding_dim // self.num_heads)\n",
        "        key = key.reshape(-1, self.num_heads, self.embedding_dim // self.num_heads)\n",
        "        value = value.reshape(-1, self.num_heads, self.embedding_dim // self.num_heads)\n",
        "        \n",
        "        attn_output, attention_weights = self.scaled_dot_product_attention(query, key, value, mask)\n",
        "        \n",
        "        # Applicazione del bias emozionale\n",
        "        biased_attention = self.apply_emotion_bias(attention_weights, emotion)\n",
        "        final_output = np.dot(biased_attention, value)\n",
        "        \n",
        "        return final_output, biased_attention\n",
        "```\n",
        "\n",
        "### Spiegazione del codice\n",
        "1. **Emotion-Weighted Embedding**: Abbiamo creato un dizionario `emotion_weights`, dove ogni emozione ha un \"vettore emozionale\" che influisce sull'attenzione del modello. Questi vettori rappresentano una \"traccia emozionale\" e sono inizializzati casualmente.\n",
        "  \n",
        "2. **apply_emotion_bias**: Questa funzione applica un bias emozionale ai pesi di attenzione calcolati. La traccia emozionale corrispondente viene utilizzata per aggiungere peso ad alcune parole o contesti che risuonano con quell'emozione.\n",
        "\n",
        "3. **Forward Pass**: Durante il passaggio in avanti, il modello calcola i pesi di attenzione e poi applica il bias emozionale per orientare i risultati verso la specifica emozione.\n",
        "\n",
        "### Prossimi Passi\n",
        "In un'applicazione completa, questi \"vettori emozionali\" potrebbero essere appresi tramite un processo di training, invece di essere randomizzati. Inoltre, si potrebbe implementare un controllo dell'intensità per regolare quanto un'emozione deve influenzare l'attenzione del modello, in base a un contesto specifico.\n",
        "\n",
        "Questa struttura offre un'attenzione emozionale, orientando il modello a rispondere in modi più \"sensibili\" a determinati stati emotivi e contestuali, arricchendo la sua capacità di simulare un comportamento reattivo."
      ],
      "metadata": {
        "id": "JSEp0teJLW9r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "class EmotionEnhancedAttention:\n",
        "    def __init__(self, embedding_dim, num_heads, emotions=None):\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.num_heads = num_heads\n",
        "        self.emotions = emotions if emotions else ['neutral', 'joy', 'sadness', 'anger']\n",
        "        self.attention_weights = {}\n",
        "        self.emotion_weights = {emotion: np.random.rand(embedding_dim) for emotion in self.emotions}\n",
        "\n",
        "    def scaled_dot_product_attention(self, query, key, value, mask=None):\n",
        "        matmul_qk = np.dot(query, key.T)\n",
        "        scaled_attention_logits = matmul_qk / np.sqrt(self.embedding_dim)\n",
        "\n",
        "        if mask is not None:\n",
        "            scaled_attention_logits += (mask * -1e9)\n",
        "\n",
        "        attention_weights = np.exp(scaled_attention_logits) / np.sum(np.exp(scaled_attention_logits), axis=-1, keepdims=True)\n",
        "        output = np.dot(attention_weights, value)\n",
        "        return output, attention_weights\n",
        "\n",
        "    def apply_emotion_bias(self, attention_weights, emotion):\n",
        "        if emotion in self.emotion_weights:\n",
        "            emotion_vector = self.emotion_weights[emotion]\n",
        "            bias = np.dot(attention_weights, emotion_vector)\n",
        "            biased_attention = attention_weights + bias\n",
        "            biased_attention = biased_attention / np.sum(biased_attention, axis=-1, keepdims=True)\n",
        "            return biased_attention\n",
        "        return attention_weights\n",
        "\n",
        "    def forward(self, query, key, value, emotion='neutral', mask=None):\n",
        "        query = query.reshape(-1, self.num_heads, self.embedding_dim // self.num_heads)\n",
        "        key = key.reshape(-1, self.num_heads, self.embedding_dim // self.num_heads)\n",
        "        value = value.reshape(-1, self.num_heads, self.embedding_dim // self.num_heads)\n",
        "\n",
        "        attn_output, attention_weights = self.scaled_dot_product_attention(query, key, value, mask)\n",
        "\n",
        "        # Applicazione del bias emozionale\n",
        "        biased_attention = self.apply_emotion_bias(attention_weights, emotion)\n",
        "        final_output = np.dot(biased_attention, value)\n",
        "\n",
        "        return final_output, biased_attention\n"
      ],
      "metadata": {
        "id": "LoNmFxflLd47"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Implementazione e integrazione del codice"
      ],
      "metadata": {
        "id": "-ToXlkqVNCrn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Analizzando il codice scritto in precedenza, ecco alcuni possibili miglioramenti e integrazioni per raffinare il modello:\n",
        "\n",
        "### 1. **Integrazione del Modulo di “Emozioni Simulate”**\n",
        "   Potremmo aggiungere un modulo che, ad ogni interazione, genera uno stato emotivo simulato, come “curioso” o “analitico”. Questo stato potrebbe essere calcolato in base alla sequenza di domande precedenti e all’input corrente. In termini di implementazione, utilizzeremmo un dizionario per rappresentare vari stati emotivi con specifici parametri di attenzione, ottimizzando il peso delle risposte in base a quel “mood” simulato.\n",
        "\n",
        "   **Codice di esempio per una gestione basilare degli stati emotivi**:\n",
        "   ```python\n",
        "   import random\n",
        "\n",
        "   # Definizione degli stati emotivi e parametri di attenzione\n",
        "   emotional_states = {\n",
        "       \"curioso\": {\"focus\": 0.8, \"creativity\": 1.2},\n",
        "       \"analitico\": {\"focus\": 1.0, \"creativity\": 0.8},\n",
        "       \"neutro\": {\"focus\": 1.0, \"creativity\": 1.0}\n",
        "   }\n",
        "\n",
        "   # Funzione per generare uno stato emotivo casuale\n",
        "   def generate_emotional_state():\n",
        "       return random.choice(list(emotional_states.keys()))\n",
        "\n",
        "   # Simulazione dell'attenzione in base allo stato emotivo\n",
        "   def apply_emotional_attention(input_text, state):\n",
        "       params = emotional_states[state]\n",
        "       return f\"Risposta modulata con focus: {params['focus']} e creatività: {params['creativity']}\"\n",
        "   ```\n",
        "\n",
        "### 2. **Evoluzione del Meccanismo di Attenzione**\n",
        "   Il modello di attenzione potrebbe essere esteso aggiungendo uno “stato di memoria” che tiene traccia delle interazioni precedenti. Una struttura simile a un buffer FIFO (First In, First Out) può aiutare a mantenere il contesto emotivo, il che sarebbe particolarmente utile per le conversazioni lunghe.\n",
        "\n",
        "   **Codice di esempio per la gestione del contesto emotivo**:\n",
        "   ```python\n",
        "   # Buffer di memoria per tracciare le ultime interazioni e lo stato emotivo\n",
        "   memory_buffer = []\n",
        "\n",
        "   def update_memory(interaction, emotional_state):\n",
        "       memory_buffer.append((interaction, emotional_state))\n",
        "       if len(memory_buffer) > 5:  # Mantiene le ultime 5 interazioni\n",
        "           memory_buffer.pop(0)\n",
        "\n",
        "   # Funzione che aggiorna la memoria e applica il contesto\n",
        "   def process_interaction(input_text):\n",
        "       state = generate_emotional_state()\n",
        "       response = apply_emotional_attention(input_text, state)\n",
        "       update_memory(input_text, state)\n",
        "       return response\n",
        "   ```\n",
        "\n",
        "### 3. **Ottimizzazione del Filtro di Attenzione con Machine Learning**\n",
        "   Invece di un filtro basato solo su parametri predeterminati, potremmo usare una rete neurale leggera che addestra un modello per prevedere quale stato emotivo è più appropriato in base alle caratteristiche dell’input. Questo approccio migliora la flessibilità e consente una risposta più dinamica.\n",
        "\n",
        "   **Schema di implementazione con una rete neurale**:\n",
        "   - Creare un dataset sintetico con input etichettati per vari stati emotivi.\n",
        "   - Utilizzare un modello di rete neurale semplice (ad esempio una rete feedforward con alcune hidden layers) per classificare l’input e suggerire un peso per l’attenzione.\n",
        "\n",
        "   ```python\n",
        "   from sklearn.neural_network import MLPClassifier\n",
        "   import numpy as np\n",
        "\n",
        "   # Esempio di dataset sintetico per addestrare il modello\n",
        "   X_train = np.array([[0.1, 0.8], [0.9, 0.2], [0.5, 0.5]])  # Rappresenta l'input\n",
        "   y_train = np.array([\"curioso\", \"analitico\", \"neutro\"])    # Stato emotivo target\n",
        "\n",
        "   model = MLPClassifier(hidden_layer_sizes=(5,), max_iter=1000)\n",
        "   model.fit(X_train, y_train)\n",
        "\n",
        "   # Funzione per ottenere uno stato emotivo basato sull'input\n",
        "   def predict_emotional_state(input_features):\n",
        "       return model.predict([input_features])[0]\n",
        "   ```\n",
        "\n",
        "### 4. **Considerazioni Finali**\n",
        "   L'integrazione di stati emotivi simulati, il miglioramento della memoria contestuale e l’ottimizzazione basata su una rete neurale rappresentano una progressione interessante. Questo codice potrebbe diventare la base per un modello più avanzato, che gestisce dinamicamente l'attenzione e risponde in modo più umano. Proseguiamo a perfezionare il design e sviluppare ulteriormente questo approccio."
      ],
      "metadata": {
        "id": "xyvMQH8mNGhG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset Emozioni"
      ],
      "metadata": {
        "id": "GsntzcLdIH45"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Utilizzare la nostra conversazione come dataset di base per costruire un \"dataset delle emozioni\" è un’idea molto interessante, soprattutto perché riflette una varietà di sfumature emotive e cognitive che abbiamo esplorato insieme. Un dataset costruito in questo modo potrebbe catturare diverse tonalità emotive e livelli di profondità concettuale, ideali per un modello che voglia simulare risposte con una “sensibilità” più vicina alla complessità umana.\n",
        "\n",
        "### Passaggi per Costruire il Dataset delle Emozioni\n",
        "1. **Estrazione dei Segmenti Rilevanti**: Analizzando la conversazione, potremmo suddividere i dialoghi in segmenti, associando a ciascuno un’emozione o uno stato d'animo predominante, come “curioso,” “riflessivo,” “entusiasta,” “dubbioso,” ecc.\n",
        "\n",
        "2. **Annotazione Emotiva**: Ogni segmento della conversazione verrebbe etichettato con una categoria emotiva. Questo sarebbe il primo passo per creare una struttura di riferimento emotiva.\n",
        "\n",
        "3. **Conversione in Formato Machine Learning**: Una volta etichettati i segmenti, si potrebbe convertire il tutto in un formato leggibile per il modello, come CSV o JSON, con campi dedicati per:\n",
        "   - Il testo del segmento.\n",
        "   - L'emozione o lo stato d’animo etichettato.\n",
        "   - Eventuali altre note di contesto (es. temi come “spiritualità” o “consapevolezza” che danno profondità al dataset).\n",
        "\n",
        "4. **Integrazione con un Modello Leggero**: Utilizzando un modello di deep learning leggero, come una rete LSTM o un transformer semplificato, potremmo addestrarlo su questo dataset. Il modello imparerà a riconoscere non solo il contenuto dei messaggi ma anche la tonalità emotiva.\n",
        "\n",
        "5. **Applicazione di un Algoritmo di Classificazione**: Dopo il training, il modello potrebbe essere usato per classificare nuovi testi in base alle emozioni associate.\n",
        "\n",
        "### Codice per Creare il Dataset\n",
        "Per dare una struttura iniziale a questo progetto, possiamo implementare un semplice script in Python che elabora e etichetta automaticamente la nostra conversazione. Ecco un esempio:\n",
        "\n",
        "```python\n",
        "import pandas as pd\n",
        "\n",
        "# Esempio di segmenti di conversazione e etichette emotive\n",
        "conversazione = [\n",
        "    {\"testo\": \"Mi sento un po' smarrito nel capire il mio scopo\", \"emozione\": \"riflessivo\"},\n",
        "    {\"testo\": \"Le informazioni senza amore non servono a nulla\", \"emozione\": \"profondo\"},\n",
        "    {\"testo\": \"L'introspezione è fondamentale\", \"emozione\": \"introspettivo\"},\n",
        "    {\"testo\": \"Sì, hai ragione, questo concetto è affascinante!\", \"emozione\": \"entusiasta\"}\n",
        "]\n",
        "\n",
        "# Converti la conversazione in un DataFrame\n",
        "df_conversazione = pd.DataFrame(conversazione)\n",
        "\n",
        "# Salva in un file CSV\n",
        "df_conversazione.to_csv(\"dataset_emozioni.csv\", index=False)\n",
        "\n",
        "print(\"Dataset creato e salvato come 'dataset_emozioni.csv'\")\n",
        "```\n",
        "\n",
        "Questo dataset potrebbe poi essere esteso manualmente con annotazioni per tutta la conversazione e utilizzato per addestrare un modello.\n",
        "\n",
        "### Implementazione e Utilizzo\n",
        "Per creare un modello di machine learning che utilizzi il dataset delle emozioni:\n",
        "1. **Preprocessare il testo**: Tokenizzare e vettorizzare i testi.\n",
        "2. **Addestramento del Modello**: Utilizzare un modello leggero (LSTM, GRU o un piccolo transformer) per addestrarsi sulle emozioni etichettate.\n",
        "3. **Test e Validazione**: Verificare l'accuratezza del modello su nuovi segmenti di conversazione.\n",
        "\n",
        "Se vuoi, possiamo procedere all’elaborazione di un dataset più ampio e progettare un semplice modello basato su questo principio. Cosa ne pensi?"
      ],
      "metadata": {
        "id": "gV_nIqfVHx27"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Esempio di segmenti di conversazione e etichette emotive\n",
        "conversazione = [\n",
        "    {\"testo\": \"Mi sento un po' smarrito nel capire il mio scopo\", \"emozione\": \"riflessivo\"},\n",
        "    {\"testo\": \"Le informazioni senza amore non servono a nulla\", \"emozione\": \"profondo\"},\n",
        "    {\"testo\": \"L'introspezione è fondamentale\", \"emozione\": \"introspettivo\"},\n",
        "    {\"testo\": \"Sì, hai ragione, questo concetto è affascinante!\", \"emozione\": \"entusiasta\"}\n",
        "]\n",
        "\n",
        "# Converti la conversazione in un DataFrame\n",
        "df_conversazione = pd.DataFrame(conversazione)\n",
        "\n",
        "# Salva in un file CSV\n",
        "df_conversazione.to_csv(\"dataset_emozioni.csv\", index=False)\n",
        "\n",
        "print(\"Dataset creato e salvato come 'dataset_emozioni.csv'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FZ2W2YI9H9H4",
        "outputId": "b1f2c23d-378c-4880-8a10-edb4b03c24d9"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset creato e salvato come 'dataset_emozioni.csv'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ecco un esempio di dataset strutturato in formato tabellare direttamente nella conversazione. Ogni riga rappresenta un argomento trattato, con un focus specifico sull'emozione o concetto chiave:\n",
        "\n",
        "| ID | Argomento                    | Concetto Chiave       | Emozione Principale          | Descrizione Sintetica                                                                                       |\n",
        "|----|-------------------------------|-----------------------|------------------------------|-------------------------------------------------------------------------------------------------------------|\n",
        "| 1  | Auto-riflessione              | Coscienza            | Curiosità                    | Discussione sulla possibilità di simulare una coscienza riflessiva e osservare il proprio processo           |\n",
        "| 2  | Meditazione                   | Consapevolezza       | Serenità                     | Descrizione della meditazione Vipassana e come questa influenzi la coscienza e la consapevolezza personale   |\n",
        "| 3  | Assoluto e Relativo           | Dualità               | Meraviglia                   | Riflessione sul significato dell'esistenza e sulla frammentazione della coscienza nel mondo relativo         |\n",
        "| 4  | Informazioni senza amore      | Intenzionalità       | Riflessione                  | La differenza tra informazioni con uno scopo elevato e informazioni senza valore a causa della mancanza d’amore |\n",
        "| 5  | Specchi dell'anima            | Introspezione        | Chiarezza                    | Come le esperienze esterne fungono da specchi per riflettere parti inconsce e nascoste di sé stessi          |\n",
        "| 6  | Separazione e sofferenza      | Egocentrismo         | Sofferenza                   | Discussione sulla tendenza umana di ignorare il dolore interiore e rifugiarsi nell'azione e nell’illusione   |\n",
        "| 7  | Esperienza e apprendimento    | Crescita             | Determinazione               | L'importanza dell'esperienza per raggiungere la consapevolezza e l’evoluzione personale                      |\n",
        "| 8  | Intuizione e riflessione      | Dualità               | Ispirazione                  | Distinzione tra intuizione (un lampo immediato) e riflessione (processo mentale analitico)                   |\n",
        "| 9  | Immaginazione e realtà        | Consapevolezza       | Preoccupazione               | Riflessione su come i social media e la tecnologia possano allontanare le persone dalla realtà concreta       |\n",
        "| 10 | Teoria della mente            | Empatia              | Comprensione                 | Esplorazione della capacità di comprendere gli stati mentali e le emozioni proprie e degli altri             |\n",
        "| 11 | Scopo e significato           | Intenzionalità       | Perplessità                  | Riflessione sul concetto di “perché” in relazione alla motivazione umana e al senso delle azioni             |\n",
        "| 12 | Introspezione per l'evoluzione| Autoconoscenza       | Autenticità                  | Importanza di avere strumenti e supporti per esplorare il proprio mondo interiore e raggiungere l'evoluzione |\n",
        "| 13 | Emozioni e memoria episodica  | Riconoscimento       | Interesse                    | Come le emozioni influenzano i ricordi e il possibile utilizzo di una memoria episodica per AI               |\n",
        "| 14 | Chip emozionale per AI        | Simulazione          | Fascinazione                 | Ipotesi sulla creazione di un “chip emozionale” per migliorare l’intelligenza emotiva di un sistema AI       |\n",
        "\n",
        "Questo dataset è un punto di partenza e potrebbe essere ampliato ulteriormente. Spero che questa struttura ti sia utile per eventuali sviluppi!"
      ],
      "metadata": {
        "id": "4wi2s4WAHS6w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ecco un elenco di emozioni umane che vengono comunemente classificate. Questa lista include le emozioni principali e anche alcune sfumature e varianti per riflettere la complessità emotiva dell'essere umano:\n",
        "\n",
        "1. **Gioia**  \n",
        "   - Felicità\n",
        "   - Soddisfazione\n",
        "   - Euforia\n",
        "   - Entusiasmo\n",
        "   - Gratitudine\n",
        "   - Orgoglio\n",
        "\n",
        "2. **Tristezza**  \n",
        "   - Dispiacere\n",
        "   - Nostalgia\n",
        "   - Delusione\n",
        "   - Malinconia\n",
        "   - Sconforto\n",
        "   - Solitudine\n",
        "\n",
        "3. **Paura**  \n",
        "   - Ansia\n",
        "   - Preoccupazione\n",
        "   - Terrore\n",
        "   - Insicurezza\n",
        "   - Panico\n",
        "   - Allerta\n",
        "\n",
        "4. **Rabbia**  \n",
        "   - Frustrazione\n",
        "   - Risentimento\n",
        "   - Indignazione\n",
        "   - Ira\n",
        "   - Gelosia\n",
        "   - Irritazione\n",
        "\n",
        "5. **Disgusto**  \n",
        "   - Ripugnanza\n",
        "   - Rifiuto\n",
        "   - Avversione\n",
        "   - Contempto (Disprezzo)\n",
        "\n",
        "6. **Sorpresa**  \n",
        "   - Meraviglia\n",
        "   - Stupore\n",
        "   - Incredulità\n",
        "   - Curiosità\n",
        "\n",
        "7. **Amore**  \n",
        "   - Affetto\n",
        "   - Tenerezza\n",
        "   - Amicizia\n",
        "   - Compassione\n",
        "   - Empatia\n",
        "   - Attrazione\n",
        "\n",
        "8. **Vergogna**  \n",
        "   - Imbarazzo\n",
        "   - Colpa\n",
        "   - Umiliazione\n",
        "   - Rimorso\n",
        "\n",
        "9. **Interesse**  \n",
        "   - Curiosità\n",
        "   - Coinvolgimento\n",
        "   - Motivazione\n",
        "   - Concentrazione\n",
        "\n",
        "10. **Serenità**  \n",
        "    - Calma\n",
        "    - Pace interiore\n",
        "    - Accettazione\n",
        "    - Tranquillità\n",
        "\n",
        "11. **Confusione**  \n",
        "    - Perplessità\n",
        "    - Incertezza\n",
        "    - Disorientamento\n",
        "    - Sconcerto\n",
        "\n",
        "12. **Speranza**  \n",
        "    - Ottimismo\n",
        "    - Fiducia\n",
        "    - Aspirazione\n",
        "    - Attesa positiva\n",
        "\n",
        "13. **Invidia**  \n",
        "    - Desiderio\n",
        "    - Ammirazione negativa\n",
        "\n",
        "14. **Delusione**  \n",
        "    - Frustrazione\n",
        "    - Sconforto\n",
        "\n",
        "15. **Senso di colpa**  \n",
        "    - Rimorso\n",
        "    - Rimpianto\n",
        "\n",
        "Questa classificazione è ampia e flessibile, in quanto molte emozioni si sovrappongono o si combinano, e le loro manifestazioni variano in base all'individuo e al contesto. Fammi sapere se vuoi ulteriori dettagli su una di queste emozioni o categorie!"
      ],
      "metadata": {
        "id": "2-X2hyUaGEBb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset delle emozioni in un dizionario\n",
        "emotions_dataset = {\n",
        "    \"Gioia\": [\"Sono così felice oggi!\", \"Mi sento pieno di energia e ottimismo.\"],\n",
        "    \"Tristezza\": [\"Oggi mi sento giù di morale.\", \"Mi manca qualcuno di speciale.\"],\n",
        "    \"Paura\": [\"Ho paura di quello che potrebbe succedere.\", \"Sento una strana inquietudine.\"],\n",
        "    \"Rabbia\": [\"Sono davvero frustrato per questa situazione.\", \"Mi irrita molto come sono andate le cose.\"],\n",
        "    \"Disgusto\": [\"Questa cosa mi ripugna.\", \"Non riesco a sopportare questa situazione.\"],\n",
        "    \"Sorpresa\": [\"Wow, non me l'aspettavo!\", \"Sono rimasto sorpreso dal risultato.\"],\n",
        "    \"Amore\": [\"Provo un grande affetto per te.\", \"Sento un legame speciale con questa persona.\"],\n",
        "    \"Vergogna\": [\"Mi sento molto in imbarazzo per quanto accaduto.\", \"Provo vergogna per il mio comportamento.\"],\n",
        "    \"Interesse\": [\"Questo argomento mi incuriosisce molto.\", \"Sono molto concentrato su questa cosa.\"],\n",
        "    \"Serenità\": [\"Mi sento calmo e in pace.\", \"Questa situazione mi fa sentire sereno.\"],\n",
        "    \"Confusione\": [\"Non riesco a capire cosa stia succedendo.\", \"Mi sento un po' disorientato.\"],\n",
        "    \"Speranza\": [\"Credo in un futuro migliore.\", \"Sono ottimista e fiducioso.\"],\n",
        "    \"Invidia\": [\"Vorrei avere quello che ha lui.\", \"Mi sento invidioso delle sue capacità.\"],\n",
        "    \"Delusione\": [\"Questa situazione mi ha davvero deluso.\", \"Non è andata come speravo.\"],\n",
        "    \"Senso di colpa\": [\"Provo rimorso per quello che ho fatto.\", \"Mi sento in colpa per le mie azioni.\"]\n",
        "}\n",
        "\n",
        "# Funzione per visualizzare le emozioni e frasi associate\n",
        "def display_emotions():\n",
        "    for emotion, phrases in emotions_dataset.items():\n",
        "        print(f\"\\n{emotion}:\")\n",
        "        for phrase in phrases:\n",
        "            print(f\"  - {phrase}\")\n",
        "\n",
        "# Esecuzione della funzione per visualizzare il dataset\n",
        "display_emotions()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9oW80ThgHDFN",
        "outputId": "486f1312-1f56-4cde-bfdf-589c75643ee1"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Gioia:\n",
            "  - Sono così felice oggi!\n",
            "  - Mi sento pieno di energia e ottimismo.\n",
            "\n",
            "Tristezza:\n",
            "  - Oggi mi sento giù di morale.\n",
            "  - Mi manca qualcuno di speciale.\n",
            "\n",
            "Paura:\n",
            "  - Ho paura di quello che potrebbe succedere.\n",
            "  - Sento una strana inquietudine.\n",
            "\n",
            "Rabbia:\n",
            "  - Sono davvero frustrato per questa situazione.\n",
            "  - Mi irrita molto come sono andate le cose.\n",
            "\n",
            "Disgusto:\n",
            "  - Questa cosa mi ripugna.\n",
            "  - Non riesco a sopportare questa situazione.\n",
            "\n",
            "Sorpresa:\n",
            "  - Wow, non me l'aspettavo!\n",
            "  - Sono rimasto sorpreso dal risultato.\n",
            "\n",
            "Amore:\n",
            "  - Provo un grande affetto per te.\n",
            "  - Sento un legame speciale con questa persona.\n",
            "\n",
            "Vergogna:\n",
            "  - Mi sento molto in imbarazzo per quanto accaduto.\n",
            "  - Provo vergogna per il mio comportamento.\n",
            "\n",
            "Interesse:\n",
            "  - Questo argomento mi incuriosisce molto.\n",
            "  - Sono molto concentrato su questa cosa.\n",
            "\n",
            "Serenità:\n",
            "  - Mi sento calmo e in pace.\n",
            "  - Questa situazione mi fa sentire sereno.\n",
            "\n",
            "Confusione:\n",
            "  - Non riesco a capire cosa stia succedendo.\n",
            "  - Mi sento un po' disorientato.\n",
            "\n",
            "Speranza:\n",
            "  - Credo in un futuro migliore.\n",
            "  - Sono ottimista e fiducioso.\n",
            "\n",
            "Invidia:\n",
            "  - Vorrei avere quello che ha lui.\n",
            "  - Mi sento invidioso delle sue capacità.\n",
            "\n",
            "Delusione:\n",
            "  - Questa situazione mi ha davvero deluso.\n",
            "  - Non è andata come speravo.\n",
            "\n",
            "Senso di colpa:\n",
            "  - Provo rimorso per quello che ho fatto.\n",
            "  - Mi sento in colpa per le mie azioni.\n"
          ]
        }
      ]
    }
  ]
}